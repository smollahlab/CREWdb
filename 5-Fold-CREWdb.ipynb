{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0725d973",
   "metadata": {},
   "source": [
    "### TESTING MODELS WITH 5-FOLD CROSS VALIDATION\n",
    "* Mollah Lab: CREWdb\n",
    "* Last Updated: 1/13/23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c182fb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing packages\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe9e0d7",
   "metadata": {},
   "source": [
    "### Data Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d39a6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading in bulk data\n",
    "data = pd.read_csv(\"./data/dataset_cleaned_397.csv\").rename(columns={'REW (Convert to Numbers)': 'REW'})\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93de392a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b296cd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping columns 'ID' and 'SYMBOL' because they are not features\n",
    "data.drop(['ID (REMOVE)', 'SYMBOL', 'HGNC approved name', 'Product'], axis = 1, inplace = True)\n",
    "data.replace('#', np.nan, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775b66cc",
   "metadata": {},
   "source": [
    "### Categorical Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fd6cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking where all data in the columns are NaN\n",
    "to_check = data.columns[5:]\n",
    "data[to_check].isna().all(1).sum()\n",
    "data.dropna(how='all', subset = to_check, inplace = True)\n",
    "print('Final Shape of Dataset:', data.shape)\n",
    "data.replace(np.nan, '-', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87317ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using one-hot encoding \n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "X = data.iloc[:, 1:]\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse = False)\n",
    "X_encoded = encoder.fit_transform(X)\n",
    "X_encoded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad50b40f",
   "metadata": {},
   "source": [
    "### Class Rebalancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58831db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import Counter\n",
    "\n",
    "y_df = data['REW']\n",
    "\n",
    "X = X_encoded\n",
    "y = y_df.values\n",
    "\n",
    "y_ = LabelEncoder().fit_transform(y)\n",
    "oversample = SMOTE(random_state=42)\n",
    "X_smote, y_smote = oversample.fit_resample(X, y_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85c45cd",
   "metadata": {},
   "source": [
    "### Methods for each ML Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb8c647",
   "metadata": {},
   "source": [
    "***Deep Neural Net (ANN)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a26248",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "    \n",
    "auc_s = []\n",
    "accuracy_s = []\n",
    "f1_s = []\n",
    "    \n",
    "    #score_id\n",
    "scores_id = []\n",
    "scores = []\n",
    "sample_ids = np.array(data.index)\n",
    "            \n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state = None)\n",
    "\n",
    "clf = MLPClassifier(hidden_layer_sizes = (100,100,), random_state=0, max_iter=5000)\n",
    "    \n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(X_smote,y_smote)):\n",
    "  X_train = X_smote[train_idx]\n",
    "  X_test = X_smote[test_idx]\n",
    "  anova_filter = SelectKBest(f_classif, k= 8)\n",
    "  var_filter = VarianceThreshold(threshold= .8 * (1 - .8))\n",
    "  anova_knn = make_pipeline(var_filter, anova_filter, clf)\n",
    "  anova_knn.fit(X_train, y_smote[train_idx])\n",
    "  y_pred_prob = anova_knn.predict_proba(X_test)\n",
    "  y_pred = anova_knn.predict(X_test)\n",
    "\n",
    "  auc = roc_auc_score(y_smote[test_idx], y_pred_prob, multi_class='ovr')\n",
    "  auc_s.append(auc)\n",
    "  accuracy_s.append(accuracy_score(y_smote[test_idx], y_pred))\n",
    "  f1_s.append(f1_score(y_smote[test_idx], y_pred, average='weighted'))      \n",
    "  scores_id.append(test_idx)\n",
    "  scores.append(y_pred_prob)\n",
    "        \n",
    "scores_id = np.concatenate(scores_id, axis=0) \n",
    "scores = np.concatenate(scores, axis=0) \n",
    "map_ids = []\n",
    "for i in range(len(sample_ids)):\n",
    "    map_ids.append(np.where(scores_id==i)[0][0])\n",
    "    map_scores = scores[map_ids]\n",
    "y_predict = np.argmax(map_scores, axis=1)\n",
    "    \n",
    "confusion_mat = confusion_matrix(y_, y_predict)\n",
    "sns.set(style=\"white\")\n",
    "labs=['Eraser','Writer', 'Reader']\n",
    "    # Generate a large random dataset\n",
    "plt.figure(figsize=(4, 4))\n",
    "sns.set(font_scale=1.2)\n",
    "ax = sns.heatmap(confusion_mat, annot=True, square=True, xticklabels=labs, yticklabels=labs, cmap='RdPu', fmt=\"d\",cbar_kws={\"shrink\": 0.85})\n",
    "ax.xaxis.tick_top()\n",
    "ax.yaxis.tick_left()\n",
    "ax.set_xticklabels(labs, fontsize=14)\n",
    "ax.set_yticklabels(labs, fontsize=14)\n",
    "plt.xlabel('Deep Neural Net', fontsize=14, labelpad=11)\n",
    "plt.yticks(rotation=0) \n",
    "plt.xticks(rotation=0) \n",
    "plt.savefig(\"dnn_5\", format=\"png\",bbox_inches='tight', dpi=600)\n",
    "\n",
    "\n",
    "plt.show()\n",
    "            \n",
    "avg_score = np.mean(auc_s)\n",
    "accuracy = np.mean(accuracy_s)\n",
    "f1 = np.mean(f1_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4d2903",
   "metadata": {},
   "source": [
    "***Naive Bayes***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5916b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state = None)\n",
    "\n",
    "model =GaussianNB()\n",
    "\n",
    "predicted_prob_dict = dict()\n",
    "auc_s = []\n",
    "accuracy_s = []\n",
    "f1_s = []\n",
    "ytest = []\n",
    "ypred = []\n",
    "    \n",
    "#score_id\n",
    "scores_id = []\n",
    "scores = []\n",
    "sample_ids = np.array(data.index)\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(X_smote, y_smote)):\n",
    "  X_train = X_smote[train_idx]\n",
    "  X_test = X_smote[test_idx]\n",
    "\n",
    "  anova_filter = SelectKBest(f_classif, k= 8)\n",
    "  var_filter = VarianceThreshold(threshold= .8 * (1 - .8))\n",
    "  anova_pipeline = make_pipeline(var_filter, anova_filter, model)\n",
    "  anova_pipeline.fit(X_train, y_smote[train_idx])\n",
    "  y_pred_prob = anova_pipeline.predict_proba(X_test)\n",
    "  y_pred = anova_pipeline.predict(X_test)\n",
    "\n",
    "  auc = roc_auc_score(y_smote[test_idx], y_pred_prob, multi_class='ovr')\n",
    "  auc_s.append(auc)\n",
    "  accuracy_s.append(accuracy_score(y_smote[test_idx], y_pred))\n",
    "  f1_s.append(f1_score(y_smote[test_idx], y_pred, average=\"weighted\"))\n",
    "  scores_id.append(test_idx)\n",
    "  scores.append(y_pred_prob)\n",
    "\n",
    "scores_id = np.concatenate(scores_id, axis=0) \n",
    "scores = np.concatenate(scores, axis=0) \n",
    "map_ids = []\n",
    "for i in range(len(sample_ids)):\n",
    "  map_ids.append(np.where(scores_id==i)[0][0])\n",
    "map_scores = scores[map_ids]\n",
    "y_predict = np.argmax(map_scores, axis=1)\n",
    "\n",
    "confusion_mat = confusion_matrix(y_, y_predict)\n",
    "\n",
    "sns.set(style=\"white\")\n",
    "labs=['Eraser','Writer', 'Reader']\n",
    "# Generate a large random dataset\n",
    "plt.figure(figsize=(4, 4))\n",
    "sns.set(font_scale=1.2)\n",
    "ax = sns.heatmap(confusion_mat, annot=True, square=True, xticklabels=labs, yticklabels=labs, cmap='RdPu', fmt=\"d\",cbar_kws={\"shrink\": 0.85})\n",
    "ax.xaxis.tick_top()\n",
    "ax.yaxis.tick_left()\n",
    "ax.set_xticklabels(labs, fontsize=14)\n",
    "ax.set_yticklabels(labs, fontsize=14)\n",
    "plt.xlabel('Naive Bayes', fontsize=14, labelpad=11)\n",
    "plt.yticks(rotation=0) \n",
    "plt.savefig(\"nb_5\", format=\"png\",bbox_inches='tight', dpi=600)\n",
    "\n",
    "avg_score = np.mean(auc_s)\n",
    "accuracy = np.mean(accuracy_s)\n",
    "f1 = np.mean(f1_s)\n",
    "\n",
    "predicted_prob_dict[fold] = y_pred_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9b028d",
   "metadata": {},
   "source": [
    "***K-Nearest Neighbors Regression***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e364faa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def knn_kfolds(X, y, n_folds, n_neighbors, new_data, old_y, random_state=None):\n",
    "    \n",
    "    auc_s = []\n",
    "    accuracy_s = []\n",
    "    f1_s = []\n",
    "    ytest = []\n",
    "    ypred = []\n",
    "    pval = []\n",
    "    \n",
    "    #score_id\n",
    "    scores_id = []\n",
    "    scores = []\n",
    "    sample_ids = np.array(new_data.index)\n",
    "    \n",
    "    kf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state = random_state)\n",
    "    \n",
    "    model = KNeighborsClassifier(n_neighbors= n_neighbors)\n",
    "    \n",
    "    \n",
    "    for fold, (train_idx, test_idx) in enumerate(kf.split(X,y)):\n",
    "        \n",
    "        scaler = preprocessing.StandardScaler().fit(X)\n",
    "        X_train_scaled = scaler.transform(X[train_idx])\n",
    "        X_test_scaled = scaler.transform(X[test_idx])\n",
    "        \n",
    "        anova_filter = SelectKBest(f_classif, k= 9)\n",
    "        var_filter = VarianceThreshold(threshold= .8 * (1 - .8))\n",
    "        anova_knn = make_pipeline(var_filter, anova_filter, model)\n",
    "        anova_knn.fit(X_train_scaled, y[train_idx])\n",
    "        y_pred_prob = anova_knn.predict_proba(X_test_scaled)\n",
    "        y_pred = anova_knn.predict(X_test_scaled)\n",
    "        \n",
    "        \n",
    "        auc = roc_auc_score(y[test_idx], y_pred_prob, multi_class='ovr')\n",
    "\n",
    "        auc_s.append(auc)\n",
    "        accuracy_s.append(accuracy_score(y[test_idx], y_pred))\n",
    "        f1_s.append(f1_score(y[test_idx], y_pred, average=\"weighted\"))\n",
    "        pval = anova_filter.pvalues_\n",
    "        \n",
    "        \n",
    "        scores_id.append(test_idx)\n",
    "        scores.append(y_pred_prob)\n",
    "        \n",
    "    scores_id = np.concatenate(scores_id, axis=0) \n",
    "    scores = np.concatenate(scores, axis=0) \n",
    "    map_ids = []\n",
    "    for i in range(len(sample_ids)):\n",
    "        map_ids.append(np.where(scores_id==i)[0][0])\n",
    "    map_scores = scores[map_ids]\n",
    "    y_predict = np.argmax(map_scores, axis=1)\n",
    "    \n",
    "    confusion_mat = confusion_matrix(old_y, y_predict)\n",
    "\n",
    "    sns.set(style=\"white\")\n",
    "    labs=['Eraser','Writer', 'Reader']\n",
    "    # Generate a large random dataset\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    sns.set(font_scale=1.2)\n",
    "    ax = sns.heatmap(confusion_mat, annot=True, square=True, xticklabels=labs, yticklabels=labs, cmap='RdPu', fmt=\"d\",cbar_kws={\"shrink\": 0.85})\n",
    "    ax.xaxis.tick_top()\n",
    "    ax.yaxis.tick_left()\n",
    "    ax.set_xticklabels(labs, fontsize=14)\n",
    "    ax.set_yticklabels(labs, fontsize=14)\n",
    "    plt.xlabel('K-Neighbors Classifier', fontsize=14, labelpad=11)\n",
    "\n",
    "    plt.yticks(rotation=0) \n",
    "    plt.xticks(rotation=0) \n",
    "    plt.show()\n",
    "    \n",
    "    avg_score = np.mean(auc_s)\n",
    "    accuracy = np.mean(accuracy_s)\n",
    "    f1 = np.mean(f1_s)\n",
    "\n",
    "    return [avg_score, accuracy, f1, confusion_mat, pval]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e159543",
   "metadata": {},
   "source": [
    "***Decision Tree***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af569bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def decision_tree(X, y, n_folds, max_depth, new_data, old_y, random_state=None):\n",
    "    \n",
    "    auc_s = [] \n",
    "    accuracy_s = []\n",
    "    f1_s = []\n",
    "    \n",
    "    #score_id\n",
    "    scores_id = []\n",
    "    scores = []\n",
    "    sample_ids = np.array(new_data.index)\n",
    "            \n",
    "    kf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state = random_state)\n",
    "\n",
    "    model = DecisionTreeClassifier(max_depth= max_depth)\n",
    "    \n",
    "    \n",
    "    for fold, (train_idx, test_idx) in enumerate(kf.split(X,y)):\n",
    "        \n",
    "        scaler = preprocessing.StandardScaler().fit(X)\n",
    "        X_train_scaled = scaler.transform(X[train_idx])\n",
    "        X_test_scaled = scaler.transform(X[test_idx])\n",
    "        \n",
    " \n",
    "        anova_filter = SelectKBest(f_classif, k= 9)\n",
    "        var_filter = VarianceThreshold(threshold=(.8 * (1 - .8)))\n",
    "        anova_knn = make_pipeline(anova_filter, model)\n",
    "        anova_knn.fit(X_train_scaled, y[train_idx])\n",
    "        y_pred_prob = anova_knn.predict_proba(X_test_scaled)\n",
    "        y_pred = anova_knn.predict(X_test_scaled)\n",
    "        \n",
    "        auc = roc_auc_score(y[test_idx], y_pred_prob, multi_class='ovr')\n",
    "\n",
    "        auc_s.append(auc)\n",
    "        accuracy_s.append(accuracy_score(y[test_idx], y_pred))\n",
    "        f1_s.append(f1_score(y[test_idx], y_pred, average='weighted'))\n",
    "     \n",
    "        scores_id.append(test_idx)\n",
    "        scores.append(y_pred_prob)\n",
    "        \n",
    "    scores_id = np.concatenate(scores_id, axis=0) \n",
    "    scores = np.concatenate(scores, axis=0) \n",
    "    map_ids = []\n",
    "    for i in range(len(sample_ids)):\n",
    "        map_ids.append(np.where(scores_id==i)[0][0])\n",
    "    map_scores = scores[map_ids]\n",
    "    y_predict = np.argmax(map_scores, axis=1)\n",
    "    \n",
    "    confusion_mat = confusion_matrix(old_y, y_predict)\n",
    "\n",
    "    sns.set(style=\"white\")\n",
    "    labs=['Eraser','Writer', 'Reader']\n",
    "    # Generate a large random dataset\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    sns.set(font_scale=1.2)\n",
    "    ax = sns.heatmap(confusion_mat, annot=True, square=True, xticklabels=labs, yticklabels=labs, cmap='RdPu', fmt=\"d\",cbar_kws={\"shrink\": 0.85})\n",
    "    ax.xaxis.tick_top()\n",
    "    ax.yaxis.tick_left()\n",
    "    ax.set_xticklabels(labs, fontsize=14)\n",
    "    ax.set_yticklabels(labs, fontsize=14)\n",
    "    plt.xlabel('Decision Tree', fontsize=14, labelpad=11)\n",
    "\n",
    "    plt.yticks(rotation=0) \n",
    "    plt.xticks(rotation=0) \n",
    "    plt.show()\n",
    "        \n",
    "    avg_score = np.mean(auc_s)\n",
    "    accuracy = np.mean(accuracy_s)\n",
    "    f1 = np.mean(f1_s)\n",
    "            \n",
    "    return [avg_score, accuracy, f1, confusion_mat]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b60cc68",
   "metadata": {},
   "source": [
    "***Random Forest***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51ece6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def random_forest(X, y, n_folds, max_depth, new_data, old_y, random_state=None):\n",
    "    \n",
    "    auc_s = []\n",
    "    accuracy_s = []\n",
    "    f1_s = []\n",
    "    \n",
    "    #score_id\n",
    "    scores_id = []\n",
    "    scores = []\n",
    "    sample_ids = np.array(new_data.index)\n",
    "            \n",
    "    kf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state = random_state)\n",
    "\n",
    "    model = RandomForestClassifier(max_depth= max_depth)\n",
    "    \n",
    "    \n",
    "    for fold, (train_idx, test_idx) in enumerate(kf.split(X,y)):\n",
    "        \n",
    "        scaler = preprocessing.StandardScaler().fit(X)\n",
    "        X_train_scaled = scaler.transform(X[train_idx])\n",
    "        X_test_scaled = scaler.transform(X[test_idx])\n",
    "        \n",
    " \n",
    "        anova_filter = SelectKBest(f_classif, k= 9)\n",
    "        var_filter = VarianceThreshold(threshold= .8 * (1 - .8))\n",
    "        anova_knn = make_pipeline(var_filter, anova_filter, model)\n",
    "        anova_knn.fit(X_train_scaled, y[train_idx])\n",
    "        y_pred_prob = anova_knn.predict_proba(X_test_scaled)\n",
    "        y_pred = anova_knn.predict(X_test_scaled)\n",
    "\n",
    "        auc = roc_auc_score(y[test_idx], y_pred_prob, multi_class='ovr')\n",
    "\n",
    "        auc_s.append(auc)\n",
    "        accuracy_s.append(accuracy_score(y[test_idx], y_pred))\n",
    "        f1_s.append(f1_score(y[test_idx], y_pred, average='weighted'))\n",
    "        \n",
    "        \n",
    "        scores_id.append(test_idx)\n",
    "        scores.append(y_pred_prob)\n",
    "        \n",
    "    scores_id = np.concatenate(scores_id, axis=0) \n",
    "    scores = np.concatenate(scores, axis=0) \n",
    "    map_ids = []\n",
    "    for i in range(len(sample_ids)):\n",
    "        map_ids.append(np.where(scores_id==i)[0][0])\n",
    "    map_scores = scores[map_ids]\n",
    "    y_predict = np.argmax(map_scores, axis=1)\n",
    "    \n",
    "    confusion_mat = confusion_matrix(old_y, y_predict)\n",
    "\n",
    "    sns.set(style=\"white\")\n",
    "    labs=['Eraser','Writer', 'Reader']\n",
    "    # Generate a large random dataset\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    sns.set(font_scale=1.2)\n",
    "    ax = sns.heatmap(confusion_mat, annot=True, square=True, xticklabels=labs, yticklabels=labs, cmap='RdPu', fmt=\"d\",cbar_kws={\"shrink\": 0.85})\n",
    "    ax.xaxis.tick_top()\n",
    "    ax.yaxis.tick_left()\n",
    "    ax.set_xticklabels(labs, fontsize=14)\n",
    "    ax.set_yticklabels(labs, fontsize=14)\n",
    "    plt.xlabel('Random Forest', fontsize=14, labelpad=11)\n",
    "\n",
    "    plt.yticks(rotation=0) \n",
    "    plt.xticks(rotation=0) \n",
    "    plt.show()\n",
    "        \n",
    "    avg_score = np.mean(auc_s)\n",
    "    accuracy = np.mean(accuracy_s)\n",
    "    f1 = np.mean(f1_s)\n",
    "            \n",
    "    return [avg_score, accuracy, f1, confusion_mat]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d1bdc5",
   "metadata": {},
   "source": [
    "**Support Vector Machine**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08b312c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "def svm_f(X, y, n_folds, new_data, old_y, random_state=None):\n",
    "    \n",
    "    auc_s = []\n",
    "    accuracy_s = []\n",
    "    f1_s = []\n",
    "    \n",
    "    #score_id\n",
    "    scores_id = []\n",
    "    scores = []\n",
    "    sample_ids = np.array(new_data.index)\n",
    "    \n",
    "    kf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state = random_state)\n",
    "\n",
    "    clf = make_pipeline(StandardScaler(), SVC(gamma='auto', probability=True))\n",
    "    \n",
    "    \n",
    "    for fold, (train_idx, test_idx) in enumerate(kf.split(X,y)):\n",
    "        \n",
    "        scaler = preprocessing.StandardScaler().fit(X)\n",
    "        X_train_scaled = scaler.transform(X[train_idx])\n",
    "        X_test_scaled = scaler.transform(X[test_idx])\n",
    "        \n",
    " \n",
    "        anova_filter = SelectKBest(f_classif, k= 9)\n",
    "        var_filter = VarianceThreshold(threshold= .8 * (1 - .8))\n",
    "        anova_knn = make_pipeline(var_filter, anova_filter, clf)\n",
    "        anova_knn.fit(X_train_scaled, y[train_idx])\n",
    "        y_pred_prob = anova_knn.predict_proba(X_test_scaled)\n",
    "        y_pred = anova_knn.predict(X_test_scaled)\n",
    "\n",
    "\n",
    "        auc = roc_auc_score(y[test_idx], y_pred_prob, multi_class='ovr')\n",
    "\n",
    "        auc_s.append(auc)\n",
    "        accuracy_s.append(accuracy_score(y[test_idx], y_pred))\n",
    "        f1_s.append(f1_score(y[test_idx], y_pred, average='weighted'))\n",
    "        \n",
    "        scores_id.append(test_idx)\n",
    "        scores.append(y_pred_prob)\n",
    "        \n",
    "    scores_id = np.concatenate(scores_id, axis=0) \n",
    "    scores = np.concatenate(scores, axis=0) \n",
    "    map_ids = []\n",
    "    for i in range(len(sample_ids)):\n",
    "        map_ids.append(np.where(scores_id==i)[0][0])\n",
    "    map_scores = scores[map_ids]\n",
    "    y_predict = np.argmax(map_scores, axis=1)\n",
    "    \n",
    "    confusion_mat = confusion_matrix(old_y, y_predict)\n",
    "\n",
    "    sns.set(style=\"white\")\n",
    "    labs=['Eraser','Writer', 'Reader']\n",
    "    # Generate a large random dataset\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    sns.set(font_scale=1.2)\n",
    "    ax = sns.heatmap(confusion_mat, annot=True, square=True, xticklabels=labs, yticklabels=labs, cmap='RdPu', fmt=\"d\",cbar_kws={\"shrink\": 0.85})\n",
    "    ax.xaxis.tick_top()\n",
    "    ax.yaxis.tick_left()\n",
    "    ax.set_xticklabels(labs, fontsize=14)\n",
    "    ax.set_yticklabels(labs, fontsize=14)\n",
    "    plt.xlabel('Support Vector Machine', fontsize=14, labelpad=11)\n",
    "\n",
    "    plt.yticks(rotation=0) \n",
    "    plt.xticks(rotation=0) \n",
    "    plt.show()\n",
    "            \n",
    "        \n",
    "    avg_score = np.mean(auc_s)\n",
    "    accuracy = np.mean(accuracy_s)\n",
    "    f1 = np.mean(f1_s)\n",
    "            \n",
    "    return [avg_score, accuracy, f1, confusion_mat]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0acd921",
   "metadata": {},
   "source": [
    "**Feed Forward Neural Network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5eb1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "def fnn_f(X, y, n_folds, new_data, old_y, random_state=None):\n",
    "    \n",
    "    auc_s = []\n",
    "    accuracy_s = []\n",
    "    f1_s = []\n",
    "    \n",
    "    #score_id\n",
    "    scores_id = []\n",
    "    scores = []\n",
    "    sample_ids = np.array(new_data.index)\n",
    "            \n",
    "    kf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state = random_state)\n",
    "\n",
    "    clf = MLPClassifier(random_state=0, max_iter=5000)\n",
    "    \n",
    "    \n",
    "    for fold, (train_idx, test_idx) in enumerate(kf.split(X,y)):\n",
    "        \n",
    "        scaler = preprocessing.StandardScaler().fit(X)\n",
    "        X_train_scaled = scaler.transform(X[train_idx])\n",
    "        X_test_scaled = scaler.transform(X[test_idx])\n",
    "        \n",
    " \n",
    "        anova_filter = SelectKBest(f_classif, k= 9)\n",
    "        var_filter = VarianceThreshold(threshold= .8 * (1 - .8))\n",
    "        anova_knn = make_pipeline(var_filter, anova_filter, clf)\n",
    "        anova_knn.fit(X_train_scaled, y[train_idx])\n",
    "        y_pred_prob = anova_knn.predict_proba(X_test_scaled)\n",
    "        y_pred = anova_knn.predict(X_test_scaled)\n",
    "\n",
    "        auc = roc_auc_score(y[test_idx], y_pred_prob, multi_class='ovr')\n",
    "\n",
    "        auc_s.append(auc)\n",
    "        accuracy_s.append(accuracy_score(y[test_idx], y_pred))\n",
    "        f1_s.append(f1_score(y[test_idx], y_pred, average='weighted'))\n",
    "        \n",
    "        scores_id.append(test_idx)\n",
    "        scores.append(y_pred_prob)\n",
    "        \n",
    "    scores_id = np.concatenate(scores_id, axis=0) \n",
    "    scores = np.concatenate(scores, axis=0) \n",
    "    map_ids = []\n",
    "    for i in range(len(sample_ids)):\n",
    "        map_ids.append(np.where(scores_id==i)[0][0])\n",
    "    map_scores = scores[map_ids]\n",
    "    y_predict = np.argmax(map_scores, axis=1)\n",
    "    \n",
    "    confusion_mat = confusion_matrix(old_y, y_predict)\n",
    "\n",
    "    sns.set(style=\"white\")\n",
    "    labs=['Eraser','Writer', 'Reader']\n",
    "    # Generate a large random dataset\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    sns.set(font_scale=1.2)\n",
    "    ax = sns.heatmap(confusion_mat, annot=True, square=True, xticklabels=labs, yticklabels=labs, cmap='RdPu', fmt=\"d\",cbar_kws={\"shrink\": 0.85})\n",
    "    ax.xaxis.tick_top()\n",
    "    ax.yaxis.tick_left()\n",
    "    ax.set_xticklabels(labs, fontsize=14)\n",
    "    ax.set_yticklabels(labs, fontsize=14)\n",
    "    plt.xlabel('Feed-Forward Neural Network', fontsize=14, labelpad=11)\n",
    "\n",
    "    plt.yticks(rotation=0) \n",
    "    plt.xticks(rotation=0) \n",
    "    plt.show()\n",
    "            \n",
    "    avg_score = np.mean(auc_s)\n",
    "    accuracy = np.mean(accuracy_s)\n",
    "    f1 = np.mean(f1_s)\n",
    "            \n",
    "    return [avg_score, accuracy, f1, confusion_mat]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24fad90",
   "metadata": {},
   "source": [
    "**Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4751ed84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def lr(X, y, n_folds, new_data, old_y, random_state=None):\n",
    "    \n",
    "    auc_s = []\n",
    "    accuracy_s = []\n",
    "    f1_s = []\n",
    "            \n",
    "    kf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state = random_state)\n",
    "\n",
    "    clf = LogisticRegression(penalty ='l2')\n",
    "    \n",
    "    #score_id\n",
    "    scores_id = []\n",
    "    scores = []\n",
    "    sample_ids = np.array(new_data.index)\n",
    "    \n",
    "    for fold, (train_idx, test_idx) in enumerate(kf.split(X,y)):\n",
    "        \n",
    "        scaler = preprocessing.StandardScaler().fit(X)\n",
    "        X_train_scaled = scaler.transform(X[train_idx])\n",
    "        X_test_scaled = scaler.transform(X[test_idx])\n",
    "        \n",
    " \n",
    "        anova_filter = SelectKBest(f_classif, k= 9)\n",
    "        var_filter = VarianceThreshold(threshold= .8 * (1 - .8))\n",
    "        anova_knn = make_pipeline(var_filter, anova_filter, clf)\n",
    "        anova_knn.fit(X_train_scaled, y[train_idx])\n",
    "        y_pred_prob = anova_knn.predict_proba(X_test_scaled)\n",
    "        y_pred = anova_knn.predict(X_test_scaled)\n",
    "\n",
    "        auc = roc_auc_score(y[test_idx], y_pred_prob, multi_class='ovr')\n",
    "\n",
    "        auc_s.append(auc)\n",
    "        accuracy_s.append(accuracy_score(y[test_idx], y_pred))\n",
    "        f1_s.append(f1_score(y[test_idx], y_pred, average='weighted'))\n",
    "        \n",
    "        scores_id.append(test_idx)\n",
    "        scores.append(y_pred_prob)\n",
    "        \n",
    "    scores_id = np.concatenate(scores_id, axis=0) \n",
    "    scores = np.concatenate(scores, axis=0) \n",
    "    map_ids = []\n",
    "    for i in range(len(sample_ids)):\n",
    "        map_ids.append(np.where(scores_id==i)[0][0])\n",
    "    map_scores = scores[map_ids]\n",
    "    y_predict = np.argmax(map_scores, axis=1)\n",
    "    \n",
    "    confusion_mat = confusion_matrix(old_y, y_predict)\n",
    "\n",
    "    sns.set(style=\"white\")\n",
    "    labs=['Eraser','Writer', 'Reader']\n",
    "    # Generate a large random dataset\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    sns.set(font_scale=1.2)\n",
    "    ax = sns.heatmap(confusion_mat, annot=True, square=True, xticklabels=labs, yticklabels=labs, cmap='RdPu', fmt=\"d\",cbar_kws={\"shrink\": 0.85})\n",
    "    ax.xaxis.tick_top()\n",
    "    ax.yaxis.tick_left()\n",
    "    ax.set_xticklabels(labs, fontsize=14)\n",
    "    ax.set_yticklabels(labs, fontsize=14)\n",
    "    plt.xlabel('Logistic Regression', fontsize=14, labelpad=11)\n",
    "\n",
    "    plt.yticks(rotation=0) \n",
    "    plt.xticks(rotation=0) \n",
    "    plt.show()\n",
    "            \n",
    "    avg_score = np.mean(auc_s)\n",
    "    accuracy = np.mean(accuracy_s)\n",
    "    f1 = np.mean(f1_s)\n",
    "            \n",
    "    return [avg_score, accuracy, f1, confusion_mat]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5a5d22",
   "metadata": {},
   "source": [
    "### Model Evaluation & Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3ec02c4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'knn_kfolds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-5f4f9dbb6b8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mknn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mknn_kfolds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_smote\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_smote\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mdt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecision_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_smote\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_smote\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mrf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_forest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_smote\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_smote\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'knn_kfolds' is not defined"
     ]
    }
   ],
   "source": [
    "#Running the ML models on the generated dataset\n",
    "\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "results = {}\n",
    "auc = []\n",
    "accuracy = []\n",
    "f1 = []\n",
    "confusion_matrices = []\n",
    "\n",
    "knn_values = []\n",
    "dt_values = []\n",
    "rf_values = []\n",
    "\n",
    "k = range(1,10)\n",
    "for i in k:\n",
    "    knn = knn_kfolds(X_smote, y_smote, 5, i, data, y_, random_state=5)\n",
    "    dt = decision_tree(X_smote, y_smote, 5, i, data, y_, random_state=5)\n",
    "    rf = random_forest(X_smote, y_smote, 5, i, data, y_, random_state=5) \n",
    "\n",
    "    knn_values.append(knn[0])\n",
    "    dt_values.append(dt[0])\n",
    "    rf_values.append(rf[0])\n",
    "\n",
    "svm = svm_f(X_smote, y_smote, 5, data, y_, random_state=5)\n",
    "fnn = fnn_f(X_smote, y_smote, 5, data, y_, random_state=5)\n",
    "lr_s = lr(X_smote, y_smote, 5, data, y_, random_state=5)\n",
    "\n",
    "auc.append(max(knn_values))\n",
    "auc.append(max(rf_values))\n",
    "auc.append(max(dt_values))\n",
    "auc.append(fnn[0])\n",
    "auc.append(lr_s[0])\n",
    "auc.append(svm[0])\n",
    "\n",
    "accuracy.append(knn[1])\n",
    "accuracy.append(dt[1])\n",
    "accuracy.append(rf[1])\n",
    "accuracy.append(fnn[1])\n",
    "accuracy.append(lr_s[1])\n",
    "accuracy.append(svm[1])\n",
    "\n",
    "f1.append(knn[2])\n",
    "f1.append(dt[2])\n",
    "f1.append(rf[2])\n",
    "f1.append(fnn[2])\n",
    "f1.append(lr_s[2])\n",
    "f1.append(svm[2])\n",
    "\n",
    "\n",
    "\n",
    "confusion_matrices.append(knn[3])\n",
    "confusion_matrices.append(dt[3])\n",
    "confusion_matrices.append(rf[3])\n",
    "confusion_matrices.append(fnn[3])\n",
    "confusion_matrices.append(lr_s[3])\n",
    "confusion_matrices.append(svm[3])\n",
    "\n",
    "results['auc'] = auc\n",
    "#results['accuracy'] = accuracy\n",
    "results['f1'] = f1\n",
    "results['accuracy'] = accuracy\n",
    "results['confusion_matrix'] = confusion_matrices\n",
    " \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbd7aaa",
   "metadata": {},
   "source": [
    "### Plotting Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1cfb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the generated confusion matrices from cell above\n",
    "sns.set(style=\"white\")\n",
    "labs=['Eraser','Writer', 'Reader']\n",
    "models = [\"K-Neighbors Classifier\", \"Decision Tree\", \"Random Forest\", \"Support Vector Machine\", \"Feed-Forward Neural Network\", \"Logistic Regression\"]\n",
    "i = 0\n",
    "img_file = \"confusion_matrices\"\n",
    "for m in results['confusion_matrix']:\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    sns.set(font_scale=1.2)\n",
    "    ax = sns.heatmap(m, annot=True, square=True, xticklabels=labs, yticklabels=labs, cmap='RdPu', fmt=\"d\",cbar_kws={\"shrink\": 0.85})\n",
    "    ax.xaxis.tick_top()\n",
    "    ax.yaxis.tick_left()\n",
    "    ax.set_xticklabels(labs, fontsize=14)\n",
    "    ax.set_yticklabels(labs, fontsize=14)\n",
    "    plt.xlabel(models[i], fontsize=14, labelpad=11)\n",
    "\n",
    "    plt.yticks(rotation=0) \n",
    "    plt.xticks(rotation=0) \n",
    "    plt.savefig(img_file + str(i), format=\"png\",bbox_inches='tight', dpi=600)\n",
    "    i = i + 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
